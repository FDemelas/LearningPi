<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Private APIs · LearningPi.jl</title><meta name="title" content="Private APIs · LearningPi.jl"/><meta property="og:title" content="Private APIs · LearningPi.jl"/><meta property="twitter:title" content="Private APIs · LearningPi.jl"/><meta name="description" content="Documentation for LearningPi.jl."/><meta property="og:description" content="Documentation for LearningPi.jl."/><meta property="twitter:description" content="Documentation for LearningPi.jl."/><meta property="og:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_private/"/><meta property="twitter:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_private/"/><link rel="canonical" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_private/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LearningPi.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Loss/">Loss Functions</a></li><li><a class="tocitem" href="../Models/">Machine Learning Models</a></li><li><a class="tocitem" href="../Sampling/">Sampling Mechanism</a></li><li><a class="tocitem" href="../Training/">Training Scripts</a></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../api/">API index</a></li><li><a class="tocitem" href="../api_public/">Public APIs</a></li><li class="is-active"><a class="tocitem" href>Private APIs</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API reference</a></li><li class="is-active"><a href>Private APIs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Private APIs</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Private-API-for-LearningPi.jl"><a class="docs-heading-anchor" href="#Private-API-for-LearningPi.jl">Private API for LearningPi.jl</a><a id="Private-API-for-LearningPi.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Private-API-for-LearningPi.jl" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.AbstractModel" href="#LearningPi.AbstractModel"><code>LearningPi.AbstractModel</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type for the Neural Networks models.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.AbstractSampler" href="#LearningPi.AbstractSampler"><code>LearningPi.AbstractSampler</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type for the Sampling functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.Corpus" href="#LearningPi.Corpus"><code>LearningPi.Corpus</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Corpus structure contains the three datasets: training, validation and test set</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.Graphormer" href="#LearningPi.Graphormer"><code>LearningPi.Graphormer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This structure provide an implementation of the main neural-network model of this project.</p><p><strong>Fields:</strong></p><ul><li><code>HiddenMap</code>: a <code>Chain</code> to map the features into the Hidden Space,</li><li><code>Graphormers</code>: a <code>GNNChain</code> to apply several Graphormer Blocks to the hidden-features representation, each component can be seen as main-block of the model,</li><li><code>Decoders</code>: a <code>Chain</code> of decoders, it should have the same size as the desired predictions,</li><li><code>Sampling</code>: sampling function,</li><li><code>n_gr</code>: number of main-blocks,</li><li><code>train_mode</code>: if the model is in training mode or not, the main change is that if off we does not sample, but just take the mean,</li><li><code>prediction_layers</code>: indexes of the main-blocks after which we want insert a Decoder to provide a Lagrangian Multipliers Prediction,</li><li><code>where_sample</code>: a <code>SamplingPosition</code> to handle different possibilities of Sampling,</li><li><code>only_last</code>: a boolean that says if we want only a single Lagragian Multipliers prediction associated to the last main-block,</li><li><code>dt</code>: deviation type.</li></ul><p>The constructor of this structure have the following </p><p><strong>Arguments:</strong></p><ul><li><code>HiddenMap</code>: as in the Fields,</li><li><code>Graphormers</code>: as in the Fields,</li><li><code>Decoders</code>: as in the Fields,</li><li><code>Sampling</code>:as in the Fields,</li><li><code>where_sample</code>:as in the Fields,</li><li><code>prediction_layers</code>: as in the Fields, by default empty, in this case we predict only in the last Graphormers layers,</li><li><code>dt</code>: as in the Fields, by default <code>cr_deviation</code>.</li></ul><p>This structure is declared as <code>Flux.functor</code> in order to efficiently and automatically implement the back-propagation. It can be called providing as input simply the graph-neural-network   (a <code>GNNGraph</code>). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.Graphormer-Tuple{Any}" href="#LearningPi.Graphormer-Tuple{Any}"><code>LearningPi.Graphormer</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: input of the NN model of type Graphormer  (a <code>GNNGraph</code>).  </li></ul><p>Forward computation of a Graphormer m, the output is the concatenation of all the multipliers predicted by the model   </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.GraphormerBlock" href="#LearningPi.GraphormerBlock"><code>LearningPi.GraphormerBlock</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that implement the basic main machine-learning block of this .</p><p><strong>Fields:</strong></p><ul><li><code>Convolution</code>: a Graph Convolutional Neural Network that performs one graph-message passing,</li><li><code>MLP</code>: a Multi-Layer-Perceptron that implement the non-linear part in parallel over all the node-hidden-features. </li></ul><p>The first constructor takes as input the following</p><p><strong>Arguments:</strong></p><ul><li><code>hidden_sample</code>: a structure composed by three boolean fields to handle the sampling positions in the  model,</li><li><code>inpOut</code>: the size  of the hidden space, </li><li><code>init</code>: initialization for the parameters of the models,</li><li><code>rng</code>: random number generator for the sampler, dropout, and all the other random components of the model,</li><li><code>pDrop</code>: dropout probability,</li><li><code>h_MLP</code>: a vector containing at each component the number of nodes in the associated layer of the hidden multi-layer-perceptron,</li><li><code>ConvLayer</code>: convolutional layer, by default is <code>GraphConv</code>,</li><li><code>act</code>: activation function for the Multi-Layer-Perceptron, by default is <code>relu</code>,</li><li><code>act_conv</code>: activation function for the Graph Convolutional Part, by default is  <code>identity</code>,</li><li><code>aggr</code>: aggregation function for the Graph Convolutional Part, by default is <code>mean</code>.</li></ul><p>The second constructor directly takes as input the Fields of the structure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.GraphormerBlock-Tuple{Any, Any}" href="#LearningPi.GraphormerBlock-Tuple{Any, Any}"><code>LearningPi.GraphormerBlock</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: a <code>GNNGraph</code>,</li><li><code>h</code>: a features matrix associated to the nodes of <code>x</code>.</li></ul><p>Computes the forward for the <code>GraphormerBlock</code>. The backward is automatically computed as long as all the operation in the forward are differentiable by <code>Zygote</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.LayerNorm" href="#LearningPi.LayerNorm"><code>LearningPi.LayerNorm</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>Fields:</strong></p><ul><li><code>eps</code>: regularization parameter,</li><li><code>d</code>: size of the input of the normalization layer. </li></ul><p>Describe the Layer Normalization for the provided parameters</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.LayerNorm-Tuple{Any}" href="#LearningPi.LayerNorm-Tuple{Any}"><code>LearningPi.LayerNorm</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Perform a Layer Normalization using <code>x</code> as input .</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.RMSNorm" href="#LearningPi.RMSNorm"><code>LearningPi.RMSNorm</code></a> — <span class="docstring-category">Type</span></header><section><div><p><strong>Fields:</strong></p><ul><li><code>eps</code>: additive regularization parameter,</li><li><code>sqrtd</code>: multiplicative regularization parameter.</li></ul><p>Describe the RMS Normalization for the provided parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.Sampler" href="#LearningPi.Sampler"><code>LearningPi.Sampler</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that implement the Sampling mechanism from a Gaussian distribution.</p><p><strong>Fields:</strong></p><ul><li><code>rng</code>: random number generator.</li></ul><p>An instantiation of this structure can be used as function. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.Sampler-Tuple{Any}" href="#LearningPi.Sampler-Tuple{Any}"><code>LearningPi.Sampler</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code> a vector (of length even), the first half components are the mean <code>μ</code> and the last hals the standard deviation <code>σ</code>.</li></ul><p>The standard deviation is bounded in [-6,2] ... magic numbers. The output is a vector of size half the size of <code>x</code> sampled from a gaussian of mean <code>μ</code> and standard deviation <code>σ</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.SamplingPosition" href="#LearningPi.SamplingPosition"><code>LearningPi.SamplingPosition</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that handle the position in the model where is performed the sample. For the moment only three alternative are available and are encoded in boolean fields.</p><p><strong>Fields:</strong></p><ul><li><code>outside</code>: if true the sampling is performed in the output space,</li><li><code>hidden_state</code>: in all the hidden states between two main blocks,</li><li><code>before_decoding</code>: in the hidden space, but only before call the decoder. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.abstract_dataset" href="#LearningPi.abstract_dataset"><code>LearningPi.abstract_dataset</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Abstract type for the dataset</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.abstract_deviation" href="#LearningPi.abstract_deviation"><code>LearningPi.abstract_deviation</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type to handle the deviation vector, i.e. the starting point from which our model produce an additive activation. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.abstract_example" href="#LearningPi.abstract_example"><code>LearningPi.abstract_example</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Abstract type for an element of a dataset</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.abstract_features_matrix" href="#LearningPi.abstract_features_matrix"><code>LearningPi.abstract_features_matrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type for the construction of the nodes-features matrix associated to the bipartite graph representation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.cr_deviation" href="#LearningPi.cr_deviation"><code>LearningPi.cr_deviation</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Type to use as deviation vector (i.e. the starting point from which our model produce an additive activation) the dual variables associated to the relaxed constraints in the optimal solution of the Continuous Relaxation. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.cr_features_matrix" href="#LearningPi.cr_features_matrix"><code>LearningPi.cr_features_matrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>with this choice the features matrix considers the informations related to the continuous relaxation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.example_gnn" href="#LearningPi.example_gnn"><code>LearningPi.example_gnn</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure to encode the examples for the training when we whant use a GNN model.</p><p><strong>Fields:</strong></p><ul><li><code>instance</code>: an instance,</li><li><code>features</code>: the features associated to the instance,	</li><li><code>gold</code>: the labels,</li><li><code>linear_relaxation</code>: the Lagrangian Subproblem value associated to the dual variable of the continuous relaxation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresCWL" href="#LearningPi.featuresCWL"><code>LearningPi.featuresCWL</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Features structure for the Capacitated Warehouse Location instance.</p><p><strong>Fields:</strong></p><p>-<code>xCR</code>: primal solution of the Linear Relaxation associated to the variables that associate one items to a pack, -<code>yCR</code>: primal solution of the Linear Relaxation associated to the variables say if we use or not a pack, -<code>λ</code>: dual solution of the Linear Relaxation associated to the packing constraints, -<code>μ</code>: dual solution of the Linear Relaxation associated to the packing constraints, -<code>objCR</code>: objective value of the Linear Relaxation, -<code>xLR</code>: primal solution of the Knapsack Lagrangian Relaxation associated to the variables that associate one items to a pack (using the dual variables λ of the linear relaxation), -<code>yLR</code>: primal solution of the Knapsack Lagrangian Relaxation associated to the variables say if we use or not a pack (using the dual variables λ of the linear relaxation), -<code>objLR</code>: objective value of the Knapsack Lagrangian Relaxation (using the dual variables λ of the linear relaxation). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresGA" href="#LearningPi.featuresGA"><code>LearningPi.featuresGA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Features structure for the Generalized Assignment instance.</p><p><strong>Fields:</strong></p><p>-<code>xCR</code>: primal solution of the Linear Relaxation associated to the variables that associate one items to a pack, -<code>λ</code>: dual solution of the Linear Relaxation associated to the packing constraints, -<code>μ</code>: dual solution of the Linear Relaxation associated to the packing constraints, -<code>objCR</code>: objective value of the Linear Relaxation, -<code>xLR</code>: primal solution of the Knapsack Lagrangian Relaxation associated to the variables that associate one items to a pack (using the dual variables λ of the linear relaxation), -<code>objLR</code>: objective value of the Knapsack Lagrangian Relaxation (using the dual variables λ of the linear relaxation). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresMCND" href="#LearningPi.featuresMCND"><code>LearningPi.featuresMCND</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct containing the information of the features for an instance.</p><p><strong>Fields:</strong></p><ul><li><code>xCR</code>: the value of the flow variables for the optimal solution of the linear relaxation,</li><li><code>yCR</code>: the value of the decision variables for the optimal solution of the linear relaxation,</li><li><code>λ</code>: the value of the dual variables associated to the flow constraints, for the optimal solution of the linear relaxation,</li><li><code>μ</code>: the value of the dual variables associated to the capacity constraints for the optimal solution of the linear relaxation,</li><li><code>objCR</code>: the objective value of the linear relaxation,</li><li><code>xLR</code>: the value of the flow variables for the optimal solution of the sub-problem for the knapsack relaxation, considering as lagrangian multiers the vector λ,</li><li><code>yLR</code>: the value of the design variables for the optimal solution of the sub-problem for the knapsack relaxation, considering as lagrangian multiers the vector λ,</li><li><code>LRarcs</code>: the objective values, for each edge, of the optimal solution of the sub-problem for the knapsack relaxation, considering as lagrangian multiers the vector λ,</li><li><code>objLR</code>: the objective value of the sub-problem for the knapsack relaxation, considering as lagrangian multiers the vector λ,</li><li><code>origins</code>: a matrix of size K×V the cost of the shortest path from the origin to the current node with costs in an edge e:  ins.r[k,e]+ins.f[e]/ins.c[e],</li><li><code>destinations</code>: a matrix of size K×V the cost of the shortest path from the current node to the destination with costs in an edge e:  ins.r[k,e]+ins.f[e]/ins.c[e],</li><li><code>distance</code>: a matrix of size V×V with the distance in terms of number of edges for the shortest path from each two nodes.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gnn_dataset" href="#LearningPi.gnn_dataset"><code>LearningPi.gnn_dataset</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure to encode the dataset composed by <code>example_gnn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.labels" href="#LearningPi.labels"><code>LearningPi.labels</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct containing the information relative to the labels</p><p><strong>Fields:</strong></p><ul><li><code>π</code>: matrix containing the gold Lagrangian multipliers. π[k, i] gives the values of the Lagrangian multiplier associated with demand k and node i,</li><li><code>x</code>: solution x of the Lagrangian problem. x[k, a] gives the value of the solution x_a^k of the Lagrangian problem L(π) for demand k and arc a,</li><li><code>y</code>: solution y of the Lagrangian problem. y[a] gives the value of the solution y_a of the Lagrangian problem L(π) for arc a,</li><li><code>LRarcs</code>: Values of the Lagrangian problem for the arcs. LRarcs[a] gives the value of subproblem L_a associated with arc a,</li><li><code>objLR</code>: Value of the Lagrangian dual problem.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.labelsCWL" href="#LearningPi.labelsCWL"><code>LearningPi.labelsCWL</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Label structure for the Capacitated Warehouse Location Problem.</p><p><strong>Fields:</strong></p><pre><code class="nohighlight hljs">-`π`: optimal lagrangian multipliers vector,
-`xLR`: primal solution of the Knapsack Lagrangian Relaxation associated to the variables that associate one items to a pack (using the optimal Lagrangian multipliers),
-`yLR`: primal solution of the Knapsack Lagrangian Relaxation associated to the variables say if we use or not a pack (using the optimal Lagrangian multipliers),
-`objLR`: optimal value of the Lagrangian Dual.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.labelsGA" href="#LearningPi.labelsGA"><code>LearningPi.labelsGA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Label structure for the Generalized Assignment Problem.</p><pre><code class="nohighlight hljs"># Fields:
-`π`: optimal lagrangian multipliers vector,
-`xLR`: primal solution of the Lagrangian Subproblem with optimal Lagrangian multipliers,
-`objLR`: optimal value of the Lagrangian Dual.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningBlockGNN" href="#LearningPi.learningBlockGNN"><code>LearningPi.learningBlockGNN</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type to type the functions that should work with Graph-Neural-Networks. This abstract type was originally tought to be used for the models that use the Block Architecture here implemented. In the current implementation it coincides more or less to <code>learningGNN</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningGNN" href="#LearningPi.learningGNN"><code>LearningPi.learningGNN</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type to type the functions that should work with Graph-Neural-Networks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningMLP" href="#LearningPi.learningMLP"><code>LearningPi.learningMLP</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that implement the learning type for a simple Multi-Layer-Perceptron (without Graph Neural Network). The features extraction is a simple manual features extraction and the model predict in parallel one value for each dualized constraints.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningMultiPredSample" href="#LearningPi.learningMultiPredSample"><code>LearningPi.learningMultiPredSample</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture similar to <code>learningSampleTransformer</code>, but predict multiple deviation using different decoders enbedded at the end of given main-blocks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningMultiPredTransformer" href="#LearningPi.learningMultiPredTransformer"><code>LearningPi.learningMultiPredTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture similar to <code>learningMultiPresSample</code>, but it does not perform sampling at all.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningSampleGasse" href="#LearningPi.learningSampleGasse"><code>LearningPi.learningSampleGasse</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture inspired from:</p><p>Gasse, M., Chételat, D., Ferroni, N., Charlin, L., and Lodi, A. Exact Combinatorial Optimization with Graph Convolutional Neural Networks. In Wallach, H., Larochelle, H., Beygelzimer, A., Alché-Buc, F. d., Fox, E., and Garnett,R. (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.</p><p>Subtype of <code>learningBlockGNN</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningSampleNair" href="#LearningPi.learningSampleNair"><code>LearningPi.learningSampleNair</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture inspired from:</p><p>Nair, V., Bartunov, S., Gimeno, F., von Glehn, I., Lichocki, P., Lobov, I., O’Donoghue, B., Sonnerat, N., Tjandraatmadja, C., Wang, P., Addanki, R., Hapuarachchi, T., Keck, T., Keeling, J., Kohli, P., Ktena, I., Li, Y., Vinyals, O., and Zwols, Y. Solving mixed integer programs using neural networks. CoRR, abs/2012.13349, 2020.</p><p>Subtype of <code>learningBlockGNN</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningSampleOutside" href="#LearningPi.learningSampleOutside"><code>LearningPi.learningSampleOutside</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture similar to <code>learningSampleTransformer</code>, but that perform instead the sampling in the lagrangian multipliers output space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningSampleTransformer" href="#LearningPi.learningSampleTransformer"><code>LearningPi.learningSampleTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture presented in:</p><p>F. Demelas, J. Le Roux, M. Lacroix, A. Parmentier &quot;Predicting Lagrangian Multipliers for Mixed Integer Linear Programs&quot;, ICML 2024.</p><p>Subtype of <code>learningBlockGNN</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningTransformer" href="#LearningPi.learningTransformer"><code>LearningPi.learningTransformer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Struct to easily construct a neural network architecture similar to <code>learningSampleTransformer</code>, but it does not perform sampling at all.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.learningType" href="#LearningPi.learningType"><code>LearningPi.learningType</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type to type the functions that should work with all the type of models and features encoding</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP" href="#LearningPi.loss_GAP"><code>LearningPi.loss_GAP</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a GAP loss. This structure can be used as function.</p><p><strong>Fields:</strong></p><ul><li><code>lr</code>: a lagranian sub-problem loss of type <code>loss_LR</code>.</li></ul><p>The constructor need no paramameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP-Tuple{Any}" href="#LearningPi.loss_GAP-Tuple{Any}"><code>LearningPi.loss_GAP</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a Lagrangian Multipliers Vector,</li><li><code>example</code>: an abstract example.</li></ul><p>Computes the value of the GAP loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP_closure" href="#LearningPi.loss_GAP_closure"><code>LearningPi.loss_GAP_closure</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a GAP closure loss. This structure can be used as function.</p><p><strong>Fields:</strong></p><ul><li><code>lr</code>: a lagranian sub-problem loss of type <code>loss_LR</code>.</li></ul><p>The constructor need no paramameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP_closure-Tuple{Any}" href="#LearningPi.loss_GAP_closure-Tuple{Any}"><code>LearningPi.loss_GAP_closure</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a Laagrangian Multipliers Vector,</li><li><code>example</code>: an abstract example.</li></ul><p>Computes the value of the GAP closure loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP_closure_factory" href="#LearningPi.loss_GAP_closure_factory"><code>LearningPi.loss_GAP_closure_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a GAP closure loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_GAP_factory" href="#LearningPi.loss_GAP_factory"><code>LearningPi.loss_GAP_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a GAP loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR" href="#LearningPi.loss_LR"><code>LearningPi.loss_LR</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a LR (CPU) loss. This structure can be used as function. The constructor need no paramameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR-Tuple{Any}" href="#LearningPi.loss_LR-Tuple{Any}"><code>LearningPi.loss_LR</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a Lagrangian Multipliers Vector,</li><li><code>example</code>: an abstract example.</li></ul><p>Computes the value of the LR (CPU) loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR_factory" href="#LearningPi.loss_LR_factory"><code>LearningPi.loss_LR_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a LR (CPU) loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR_gpu" href="#LearningPi.loss_LR_gpu"><code>LearningPi.loss_LR_gpu</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a LR gpu loss. This structure can be used as function. The constructor need no paramameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR_gpu-Tuple{Any}" href="#LearningPi.loss_LR_gpu-Tuple{Any}"><code>LearningPi.loss_LR_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a Lagrangian Multipliers Vector,</li><li><code>example</code>: an abstract example.</li></ul><p>Computes the value of the LR GPU loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_LR_gpu_factory" href="#LearningPi.loss_LR_gpu_factory"><code>LearningPi.loss_LR_gpu_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a LR GPU loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_hinge" href="#LearningPi.loss_hinge"><code>LearningPi.loss_hinge</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure of parameters for loss obtained as the inverse of the sub-problem obj value.</p><p><strong>Fields:</strong></p><p>-<code>α</code>: regularization term. Warning: for the moment this parameter not used!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_hinge-Tuple{Any}" href="#LearningPi.loss_hinge-Tuple{Any}"><code>LearningPi.loss_hinge</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: lagrangian multipliers vector candidate,</li><li><code>example</code>: dataset sample object.</li></ul><p>Computes the value of the Hinge loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_mse" href="#LearningPi.loss_mse"><code>LearningPi.loss_mse</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a MSE loss. This structure can be used as function. The constructor need no paramameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_mse-Tuple{Any}" href="#LearningPi.loss_mse-Tuple{Any}"><code>LearningPi.loss_mse</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: lagrangian multipliers vector candidate,</li><li><code>example</code>: dataset sample object,</li></ul><p>-<code>_</code>: loss parameters, it should be a structure of type MSELoss.   </p><p>Returns the loss function value obtained taking the MSE beteern the predicted Lagrangian multipliers <code>π</code> and the optimal ones in <code>example</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_mse_factory" href="#LearningPi.loss_mse_factory"><code>LearningPi.loss_mse_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a MSE loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_multi_LR" href="#LearningPi.loss_multi_LR"><code>LearningPi.loss_multi_LR</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that realize a multi-prediction LR (CPU) loss. This structure can be used as function.</p><p><strong>Fields:</strong></p><ul><li><code>α</code>: a penalization parameter to weight the different predictions, by default is 0.5,</li><li><code>lr</code>: a loss of type <code>loss_LR</code>, automatically constructed.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_multi_LR-Tuple{AbstractVector}" href="#LearningPi.loss_multi_LR-Tuple{AbstractVector}"><code>LearningPi.loss_multi_LR</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a Lagrangian Multipliers Vector,</li><li><code>example</code>: an abstract example.</li></ul><p>Computes the value of the multi-prediction LR (CPU) loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.loss_multi_LR_factory" href="#LearningPi.loss_multi_LR_factory"><code>LearningPi.loss_multi_LR_factory</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure that should be used to construct a multi-prediction LR (CPU) loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.lr_features_matrix" href="#LearningPi.lr_features_matrix"><code>LearningPi.lr_features_matrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>with this choice the features matrix considers the informations related to the continuous relaxation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.without_cr_features_matrix" href="#LearningPi.without_cr_features_matrix"><code>LearningPi.without_cr_features_matrix</code></a> — <span class="docstring-category">Type</span></header><section><div><p>with this choice the features matrix does not considers the informations related to the continuous relaxation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.zero_deviation" href="#LearningPi.zero_deviation"><code>LearningPi.zero_deviation</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Type to use as deviation vector (i.e. the starting point from which our model produce an additive activation) the all zeros vector. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ChainRulesCore.rrule-Tuple{LearningPi.loss_LR, AbstractArray}" href="#ChainRulesCore.rrule-Tuple{LearningPi.loss_LR, AbstractArray}"><code>ChainRulesCore.rrule</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Compute the value of the Learning by Experience loss (usining the inverse of value of the sub-problem) and its pullback function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ChainRulesCore.rrule-Tuple{LearningPi.loss_LR_gpu, AbstractArray}" href="#ChainRulesCore.rrule-Tuple{LearningPi.loss_LR_gpu, AbstractArray}"><code>ChainRulesCore.rrule</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Compute the value of the Learning by Experience loss (usining the inverse of value of the sub-problem) and its pullback function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ChainRulesCore.rrule-Tuple{LearningPi.loss_hinge, AbstractArray}" href="#ChainRulesCore.rrule-Tuple{LearningPi.loss_hinge, AbstractArray}"><code>ChainRulesCore.rrule</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Compute the value of the Hinge Loss and its pullback function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Flux.cpu-Tuple{LearningPi.Graphormer}" href="#Flux.cpu-Tuple{LearningPi.Graphormer}"><code>Flux.cpu</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>m</code>: a <code>Graphormer</code> model.</li></ul><p>Extends the <code>cpu</code> function of <code>Flux</code> to be applied to <code>Graphormer</code> model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Flux.gpu-Tuple{LearningPi.Graphormer}" href="#Flux.gpu-Tuple{LearningPi.Graphormer}"><code>Flux.gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>m</code>: a <code>Graphormer</code> model.</li></ul><p>Extends the <code>gpu</code> function of <code>Flux</code> to be applied to <code>Graphormer</code> model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.LM_sign-Tuple{Any, Instances.instanceGA}" href="#LearningPi.LM_sign-Tuple{Any, Instances.instanceGA}"><code>LearningPi.LM_sign</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`x`: an unsigned Lagrangian multipliers vector,
-`ins`: an instances (of type `instanceGA`).</code></pre><p>Return the Lagrangian Multipliers <code>-softplus(x)</code> as for the way in which is encoded GA we have non-positive Lagrangian multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.LM_sign-Tuple{Any, abstractInstanceMCND}" href="#LearningPi.LM_sign-Tuple{Any, abstractInstanceMCND}"><code>LearningPi.LM_sign</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`x`: an unsigned Lagrangian multipliers vector,
-`ins`: an instances (of type `abstractInstanceMCND`).</code></pre><p>Return the Lagrangian Multipliers <code>x</code> as for MCND we have no sign constraint..</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.LM_sign-Tuple{Any, instanceCWL}" href="#LearningPi.LM_sign-Tuple{Any, instanceCWL}"><code>LearningPi.LM_sign</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`x`: an unsigned Lagrangian multipliers vector,
-`ins`: an instances (of type `instanceCWL`).</code></pre><p>Return the Lagrangian Multipliers <code>x</code> as for the way in which is encoded CWL we have no-sign constraints for the Lagrangian multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.adj_var_constr-Tuple{Instances.instanceGA}" href="#LearningPi.adj_var_constr-Tuple{Instances.instanceGA}"><code>LearningPi.adj_var_constr</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`ins`: an instances (of type `abstractInstanceGA`),</code></pre><p>return the adjaciency matrix associated to the dualized constrants and the variables nodes in the bipartite graph representation. The component associated to a couple <code>(constraint,variable)</code> is equal to <code>1</code> if and only if the <code>variable</code> has non-null coefficient in <code>constraint</code>. Otherwise is zero.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.adj_var_constr-Tuple{abstractInstanceMCND}" href="#LearningPi.adj_var_constr-Tuple{abstractInstanceMCND}"><code>LearningPi.adj_var_constr</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>ins</code>: an instances (of type <code>abstractInstanceMCND</code>).</p><p>Return the adjaciency matrix associated to the dualized constrants and the variables nodes in the bipartite graph representation. The component associated to a couple <code>(constraint,variable)</code> is equal to <code>1</code> if and only if the <code>variable</code> has non-null coefficient in <code>constraint</code>. Otherwise is zero.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.adj_var_constr-Tuple{instanceCWL}" href="#LearningPi.adj_var_constr-Tuple{instanceCWL}"><code>LearningPi.adj_var_constr</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`ins`: an instances (of type `instanceCWL`).</code></pre><p>return the adjaciency matrix associated to the dualized constrants and the variables nodes in the bipartite graph representation. The component associated to a couple <code>(constraint,variable)</code> is equal to <code>1</code> if and only if the <code>variable</code> has non-null coefficient in <code>constraint</code>. Otherwise is zero.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.aggregate_features-Tuple{abstractInstance, Any, Any}" href="#LearningPi.aggregate_features-Tuple{abstractInstance, Any, Any}"><code>LearningPi.aggregate_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure,</li><li><code>varFeatures</code>: features matrix for the variables of the problem,</li><li><code>G</code>: adjaciency matrix that have a one in the position for the couple (variable, constraint) if and only if the variable is used in the constraint.</li></ul><p>Returns the features associated to the dualized constraint of the instance <code>ins</code> obtained by an aggregation of <code>varFeatures</code> with respect to the neighbourhoods induced by the adjaciency matrix <code>G</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.compareWithBests-Tuple{Dict, Dict, Any, Any}" href="#LearningPi.compareWithBests-Tuple{Dict, Dict, Any, Any}"><code>LearningPi.compareWithBests</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>currentMetrics</code> : a dictionary of Float, </li><li><code>bestMetrics</code> : a dictionary of Float, </li><li><code>nn</code> : a neural network,</li><li><code>endString</code> : a string used to memorize the best models.</li></ul><p>This function compare all the values in <code>bestMetrics</code> with the ones in <code>currentMetrics</code> (that corresponds to the same key). If some value in <code>currentMetrics</code> is better, then we update the correspondent value in <code>bestMetrics</code> and we save the model in a bson file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createEmptyDataset-Tuple{LearningPi.learningGNN}" href="#LearningPi.createEmptyDataset-Tuple{LearningPi.learningGNN}"><code>LearningPi.createEmptyDataset</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learning Multi Layer Perceptron type.</li></ul><p>Create an empty dataset for the Graph Neural network learning type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createEmptyDataset-Tuple{LearningPi.learningMLP}" href="#LearningPi.createEmptyDataset-Tuple{LearningPi.learningMLP}"><code>LearningPi.createEmptyDataset</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learning Multi Layer Perceptron type.</li></ul><p>Create an empty dataset for the  Multi Layer Perceptron learning type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_features-Tuple{Instances.instanceGA}" href="#LearningPi.create_features-Tuple{Instances.instanceGA}"><code>LearningPi.create_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">	- `ins`: instance object, it should be of type instanceGA.

read the features and returns a features structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_features-Tuple{cpuInstanceMCND}" href="#LearningPi.create_features-Tuple{cpuInstanceMCND}"><code>LearningPi.create_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, should be of type cpuInstanceMCND.</li></ul><p>Create and return as output a features structure for the MCND instance <code>ins</code>.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_features-Tuple{instanceCWL}" href="#LearningPi.create_features-Tuple{instanceCWL}"><code>LearningPi.create_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `ins`: instance object, it should be of type `instanceCWL`. 

Solves the Continuous Relaxation and the Lagrangian Sub-Problem considering as Lagrangian Multipliers
the dual variables associated to the relaxed constraints and then returns a features structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model_gasse" href="#LearningPi.create_model_gasse"><code>LearningPi.create_model_gasse</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>where_sample</code>: a structure composed by three booleans to say where perform sampling, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>nBlocks</code>: number of main-blocks that compose the core part of the encoder,</li><li><code>nNodes</code>: dimension of the hidden-space for the features representation,</li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>act</code>: activation function for the parallel MLP, by default <code>relu</code>,</li><li><code>act_conv</code>: activation function for the Graph-Convolutional Layers, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>, </li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default <code>[100,250,500]</code>,</li><li><code>hH</code>:   a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, by default <code>[500]</code> ,</li><li><code>hF</code>:  a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>pDrop</code>: drop-out parameter, by default  <code>0.001</code> (unused in this implementation, will be removed soon),</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>aggr</code>: the aggregation function, by default <code>mean</code>,</li><li><code>prediction_layers</code>: a vector that contains the indexes of the layers in which we want perform a prediction, by default <code>[]</code>, in this case we use the decoder only in the last main-block of the Graphormer.</li></ul><p>Return a model as defined in <code>Graphormer.jl</code> using the provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model_nair" href="#LearningPi.create_model_nair"><code>LearningPi.create_model_nair</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>where_sample</code>: a structure composed by three booleans to say where perform sampling, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>nBlocks</code>: number of main-blocks that compose the core part of the encoder,</li><li><code>nNodes</code>: dimension of the hidden-space for the features representation,</li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>act</code>: activation function for the parallel MLP, by default <code>relu</code>,</li><li><code>act_conv</code>: activation function for the Graph-Convolutional Layers, by default <code>relu</code> (unused in this implementation, will be removed soon),</li><li><code>seed</code>: random generation seed, by default <code>1</code>, </li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default <code>[100,250,500]</code>,</li><li><code>hH</code>:   a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, by default <code>[500]</code> ,</li><li><code>hF</code>:  a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>pDrop</code>: drop-out parameter, by default  <code>0.001</code> (unused in this implementation, will be removed soon),</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>;</li><li><code>aggr</code>: the aggregation function, by default <code>mean</code>,</li><li><code>prediction_layers</code>: a vector that contains the indexes of the layers in which we want perform a prediction, by default <code>[]</code>, in this case we use the decoder only in the last main-block of the Graphormer.</li></ul><p>returns a model as defined in <code>Graphormer.jl</code> using the provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_rms-Tuple{Any}" href="#LearningPi.create_rms-Tuple{Any}"><code>LearningPi.create_rms</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>d</code>: size of input in the input layers.</li></ul><p>return a RMSNorm function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.deviationFrom-Tuple{Any, LearningPi.cr_deviation}" href="#LearningPi.deviationFrom-Tuple{Any, LearningPi.cr_deviation}"><code>LearningPi.deviationFrom</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: the bipartite-graph representation of the instance.</li></ul><p>For the <code>cr_deviation</code> it returns the dual variables associated to the dualized constraints in the optimal solution of the continuous relaxation, taking the good components from the nodes features matrix in the bipartite-graph representation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.deviationFrom-Tuple{Any, LearningPi.zero_deviation}" href="#LearningPi.deviationFrom-Tuple{Any, LearningPi.zero_deviation}"><code>LearningPi.deviationFrom</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: the bipartite-graph representation of the instance.</li></ul><p>For the <code>zero_deviation</code> it returns an all-zeros vector with the correct size. The size will be the same as the dual variables associated to the dualized constraints in the optimal solution of the continuous relaxation, taking the good components from the nodes features matrix in the bipartite-graph representation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_matrix-Tuple{Instances.instanceGA, Any, LearningPi.abstract_features_matrix}" href="#LearningPi.features_matrix-Tuple{Instances.instanceGA, Any, LearningPi.abstract_features_matrix}"><code>LearningPi.features_matrix</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, it should be a sub-type of instanceGA,</li><li><code>featObj</code>: features object containing all the characteristics,</li><li><code>fmt</code>: features matrix type.</li></ul><p>Construct the matrix of the features for a bipartite-graph representation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_matrix-Tuple{abstractInstanceMCND, LearningPi.featuresMCND, LearningPi.abstract_features_matrix}" href="#LearningPi.features_matrix-Tuple{abstractInstanceMCND, LearningPi.featuresMCND, LearningPi.abstract_features_matrix}"><code>LearningPi.features_matrix</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, it should be a sub-type of abstractInstanceMCND,</li><li><code>featObj</code>: features object containing all the characteristics, </li><li><code>fmt</code>: features matrix type.</li></ul><p>Construct the matrix of the features for a bipartite-graph representation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_matrix-Tuple{instanceCWL, Any, LearningPi.abstract_features_matrix}" href="#LearningPi.features_matrix-Tuple{instanceCWL, Any, LearningPi.abstract_features_matrix}"><code>LearningPi.features_matrix</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, it should be a sub-type of instanceCWL,</li><li><code>featObj</code>: features object containing all the characteristics,</li><li><code>fmt</code>: features matrix type.</li></ul><p>Construct the matrix of the features for a bipartite-graph representation of the instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_variables-Tuple{Instances.instanceGA, Any, Any}" href="#LearningPi.features_variables-Tuple{Instances.instanceGA, Any, Any}"><code>LearningPi.features_variables</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>ins</code>: an instances (of type <code>abstractInstanceGA</code>),</p><ul><li><code>featObj</code>: features encoded in an apposite structure,</li><li><code>G</code>: adjaciency matrix that have a one in the position for the couple (variable, constraint) if and only if the variable is used in the constraint.</li></ul><p>Returns the features associated to the variables in <code>ins</code> using the structure of the instance and the <code>featObj</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_variables-Tuple{abstractInstanceMCND, Any, Any}" href="#LearningPi.features_variables-Tuple{abstractInstanceMCND, Any, Any}"><code>LearningPi.features_variables</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure (of type <code>abstractInstanceMCND</code>),</li><li><code>featObj</code>: features encoded in an apposite structure,</li><li><code>G</code>: adjaciency matrix that have a one in the position for the couple (variable, constraint) if and only if the variable is used in the constraint.</li></ul><p>Returns the features associated to the variables in <code>ins</code> using the structure of the instance and the <code>featObj</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.features_variables-Tuple{instanceCWL, Any, Any}" href="#LearningPi.features_variables-Tuple{instanceCWL, Any, Any}"><code>LearningPi.features_variables</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>ins</code>: an instances (of type <code>instanceCWL</code>),</p><ul><li><code>featObj</code>: features encoded in an apposite structure,</li><li><code>G</code>: adjaciency matrix that have a one in the position for the couple (variable, constraint) if and only if the variable is used in the constraint.</li></ul><p>Returns the features associated to the variables in <code>ins</code> using the structure of the instance and the <code>featObj</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.forwardBackward" href="#LearningPi.forwardBackward"><code>LearningPi.forwardBackward</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>loss</code>: a structure that contains the parameters α and β of the loss,</li><li><code>trainSet</code>: the training dataset structure,</li><li><code>nn</code>: the neural network model,</li><li><code>currentMetrics</code>: a dictionary of Float, </li><li><code>opt</code>: the optimizer used for the training,</li><li><code>loss</code>: the loss function,</li><li><code>epoch</code>: the current epoch,</li><li><code>lt</code>: learning type object,   </li><li><code>dt</code>: deviation type (0 or duals of the continuous relaxation).</li></ul><p>This function performs the forward-backward pass for the training considering a generic loss and a generic learning type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.forwardBackward-Tuple{Any, LearningPi.Graphormer, Any, Any, Any, Int64, LearningPi.learningType, LearningPi.abstract_deviation}" href="#LearningPi.forwardBackward-Tuple{Any, LearningPi.Graphormer, Any, Any, Any, Int64, LearningPi.learningType, LearningPi.abstract_deviation}"><code>LearningPi.forwardBackward</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>trainSet</code>: the (training) set,</li><li><code>nn</code>: a model of type <code>Graphormer</code>,</li><li><code>currentMetrics</code>: a dictionary that contains the metrix of the current iteration,</li><li><code>opt</code>: an <code>Optimiser</code>,</li><li><code>loss</code>: loss function,</li><li><code>epoch</code>: the epcoh counter (this patameter is unsued in the current implementation and it will be soon removed), </li><li><code>lt</code>: learning type (this patameter is unsued in the current implementation and it will be soon removed),</li><li><code>dt</code>: deviation type  (this patameter is unsued in the current implementation and it will be soon removed).</li></ul><p>This function performs the forward and backward pass for the model <code>nn</code> over all the (training) set <code>trainSet</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gap-Tuple{LearningPi.abstract_example, Real, Real, Real}" href="#LearningPi.gap-Tuple{LearningPi.abstract_example, Real, Real, Real}"><code>LearningPi.gap</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>example</code>: the current example (dataset point),</li><li><code>objPred</code>: the current obective for the example,</li><li><code>objGold</code>: the optimal value of the Lagrangian Dual,</li><li><code>nInst</code>: the number of the instances in the set.</li></ul><p>Computes the GAP of the instance in the <code>example</code> using the predicted objective <code>objPred</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gap_closure-Tuple{LearningPi.abstract_example, Real, Real, Real}" href="#LearningPi.gap_closure-Tuple{LearningPi.abstract_example, Real, Real, Real}"><code>LearningPi.gap_closure</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>example</code>: the current example (dataset point),</li><li><code>objPred</code>: the current obective for the example,</li><li><code>objGold</code>: the optimal value of the Lagrangian Dual,</li><li><code>nInst</code>: the number of the instances in the set.</li></ul><p>Computes the closure GAP of the instance in the <code>example</code> using the predicted objective <code>objPred</code>. The closure is w.r.t. the value of the Lagrangian Sub-Problem, solved with the dual variables of the continuous relaxation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_cr_features-Tuple{LearningPi.cr_features_matrix, Any, Any, Any}" href="#LearningPi.get_cr_features-Tuple{LearningPi.cr_features_matrix, Any, Any, Any}"><code>LearningPi.get_cr_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it shoul be <code>cr_features_matrix</code>) </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_cr_features-Tuple{LearningPi.lr_features_matrix, Any, Any, Any}" href="#LearningPi.get_cr_features-Tuple{LearningPi.lr_features_matrix, Any, Any, Any}"><code>LearningPi.get_cr_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>lr_features_matrix</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_cr_features-Tuple{LearningPi.without_cr_features_matrix, Any, Any, Any}" href="#LearningPi.get_cr_features-Tuple{LearningPi.without_cr_features_matrix, Any, Any, Any}"><code>LearningPi.get_cr_features</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>without_cr_features_matrix</code>).</p><p>in this case we have no CR features and it returns an empty vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_device-Tuple{LearningPi.abstract_loss}" href="#LearningPi.get_device-Tuple{LearningPi.abstract_loss}"><code>LearningPi.get_device</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `_`: the loss parameters.

returns the device (cpu/gpu) used to compute the loss.
For a general loss will be CPU.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_device-Tuple{LearningPi.loss_LR_gpu}" href="#LearningPi.get_device-Tuple{LearningPi.loss_LR_gpu}"><code>LearningPi.get_device</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: loss function.</li></ul><p>returns the device to use with this loss. implementationn this case GPU.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_model-Tuple{Flux.Chain}" href="#LearningPi.get_model-Tuple{Flux.Chain}"><code>LearningPi.get_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`nn`: neural network model.</code></pre><p>In this case only returns the model <code>nn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_model-Tuple{LearningPi.Graphormer}" href="#LearningPi.get_model-Tuple{LearningPi.Graphormer}"><code>LearningPi.get_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`nn`: neural network model of type `Graphormer`.</code></pre><p>Returns a cpu version of the model that can be saved using a bson file.    </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_parameters" href="#LearningPi.get_parameters"><code>LearningPi.get_parameters</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>nn</code> : neural network,</li><li><code>lt</code> : learning type,</li><li><code>f</code> :  useless parameter, removed soon.</li></ul><p>Returns the model parameters of <code>nn</code> in the case in which nn belsong to <code>lt</code> learning type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_parameters-Tuple{LearningPi.learningType}" href="#LearningPi.get_parameters-Tuple{LearningPi.learningType}"><code>LearningPi.get_parameters</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>nn</code>: a model, sub-type of <code>learningType</code>.</li></ul><p>implementation for the function that. The general rule is that <code>nn</code> is a model and we can directly call the function <code>Flux.params</code> This abstract implementation will be soon removed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_λ-Tuple{Any}" href="#LearningPi.get_λ-Tuple{Any}"><code>LearningPi.get_λ</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: the bipartite-graph representation of the instance.</li></ul><p>Returns the dual variables associated to the dualized constraints in the optimal solution of the continuous relaxation, taking the good components from the nodes features matrix in the bipartite-graph representation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.get_λ-Tuple{CUDA.CuArray}" href="#LearningPi.get_λ-Tuple{CUDA.CuArray}"><code>LearningPi.get_λ</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>x</code>: a GPU features vector.</li></ul><p>Return the dual variables of the CR associated to the dualized constraints. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, Instances.cpuInstanceGA}" href="#LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, Instances.cpuInstanceGA}"><code>LearningPi.gradient_lsp</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `x`: the solution of the Lagrangian Sub-problem,
- `ins`: a cpuInstanceCWL structure.</code></pre><p>This function compute and returns the gradient of the sub-problem objective function w.r.t. the Lagrangian Multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, Instances.gpuMCNDinstance}" href="#LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, Instances.gpuMCNDinstance}"><code>LearningPi.gradient_lsp</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `x`: the solution of the Lagrangian Sub-problem,
- `ins`: a cpuInstanceCWL structure.</code></pre><p>This function compute and returns the gradient of the sub-problem objective function w.r.t. the Lagrangian Multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, cpuInstanceCWL}" href="#LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, cpuInstanceCWL}"><code>LearningPi.gradient_lsp</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `x`: the solution of the Lagrangian Sub-problem,
- `ins`: a cpuInstanceCWL structure.</code></pre><p>This function compute and returns the gradient of the sub-problem objective function w.r.t. the Lagrangian Multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, cpuInstanceMCND}" href="#LearningPi.gradient_lsp-Tuple{AbstractVecOrMat, cpuInstanceMCND}"><code>LearningPi.gradient_lsp</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- `x`: the solution of the Lagrangian Sub-problem,
- `ins`: a cpuInstanceMCND structure.</code></pre><p>This function compute and returns the gradient of the sub-problem objective function w.r.t. the Lagrangian Multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.load_model-Tuple{Any, LearningPi.learningMLP}" href="#LearningPi.load_model-Tuple{Any, LearningPi.learningMLP}"><code>LearningPi.load_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`nn`: neural network model,
-`lt`: learning type (of type `learningMLP`).</code></pre><p>In this case only returns the model <code>nn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.load_model-Tuple{LearningPi.Graphormer, LearningPi.learningGNN}" href="#LearningPi.load_model-Tuple{LearningPi.Graphormer, LearningPi.learningGNN}"><code>LearningPi.load_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`nn`: neural network model of type `Graphormer`,
-`lt`: learning type (of type `learningGNN`).</code></pre><p>In this case only returns the model <code>nn</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.preprocess_weight-Tuple{LearningPi.abstract_features_matrix, Real}" href="#LearningPi.preprocess_weight-Tuple{LearningPi.abstract_features_matrix, Real}"><code>LearningPi.preprocess_weight</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>without_cr_features_matrix</code>).</p><p>Preprocess the edge weights of the bipartite graph representation of the instance. One edges correspond to a pair (variable, constraint). In this project are for the moment implemented three choices: 	- all ones weights, 	- weights equal to the coefficients of the variable in the constraints, 	- a modification of the last to assure positive weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.printBests-Tuple{Dict, String}" href="#LearningPi.printBests-Tuple{Dict, String}"><code>LearningPi.printBests</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>bestMetrics</code>: a dictionary of float that contains the best values</li></ul><pre><code class="nohighlight hljs">		   find in the training for altypel the considered metrics,</code></pre><ul><li><code>path</code>: location where print the results in a file.				</li></ul><p>Takes as input the dictionary of the best metrics and print the values in standard output and in a file defined by the <code>path</code>.                </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.printMetrics-Tuple{Dict}" href="#LearningPi.printMetrics-Tuple{Dict}"><code>LearningPi.printMetrics</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>currentMetrics</code>: a dictionary of Float.</li></ul><p>This function takes as input the dictionary of the metrics and print the values associated to training and validation sets.    </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.print_best_models-Tuple{String, Dict}" href="#LearningPi.print_best_models-Tuple{String, Dict}"><code>LearningPi.print_best_models</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>endString</code>: Path where save the models,</li><li><code>bestModels</code>: Dictionary of the best models (w.r.t different metrics) found so far.</li></ul><p>Print in a file BSON, located in the folder <code>endString</code> the best model found so far.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.print_json-Tuple{Any, Any, Any, Any, cpuMCNDinstanceFactory}" href="#LearningPi.print_json-Tuple{Any, Any, Any, Any, cpuMCNDinstanceFactory}"><code>LearningPi.print_json</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, it should be of type <code>cpuMCNDinstance</code>,</li><li><code>lab</code>: labels structure, it should be of type <code>labelsMCND</code>,</li><li><code>feat</code>: features structure, it should be of type <code>featuresMCND</code>,</li><li><code>fileName</code>: the path to the file json where print the data,</li><li><code>factory</code>: instance factory should be of type <code>cpuMCNDinstanceFactory</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.print_json-Tuple{Instances.instanceGA, LearningPi.labelsGA, LearningPi.featuresGA, String}" href="#LearningPi.print_json-Tuple{Instances.instanceGA, LearningPi.labelsGA, LearningPi.featuresGA, String}"><code>LearningPi.print_json</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>ins</code>: instance structure, it should be of type &lt;: instanceGA,</li><li><code>lab</code>: labels structure, it should be of type labelsGA,</li><li><code>feat</code>: features structure, it should be of type featuresGA,</li><li><code>fileName</code>: the path to the file json where print the data.</li></ul><p>Print in a <code>JSON</code> format the information contained in <code>ins</code>,<code>feat</code> and <code>lab</code>, in a file in <code>fileName</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.print_json-Tuple{instanceCWL, LearningPi.labelsCWL, LearningPi.featuresCWL, String}" href="#LearningPi.print_json-Tuple{instanceCWL, LearningPi.labelsCWL, LearningPi.featuresCWL, String}"><code>LearningPi.print_json</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>ins</code>: instance structure, it should be of type  of <code>instanceCWL</code>,</p><ul><li><code>lab</code>: labels structure, it should be of type <code>labelsCWL</code>,</li><li><code>feat</code>: features structure, it should be of type <code>featuresCWL</code>,</li><li><code>fileName</code>: the path to the file json where print the data.</li></ul><p>Print the information provided in the instance <code>ins</code>, the labels <code>lab</code> and the features <code>feat</code> in a JSON file located in the path <code>fileName</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.read_labels-Tuple{String, Instances.instanceGA}" href="#LearningPi.read_labels-Tuple{String, Instances.instanceGA}"><code>LearningPi.read_labels</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">	- `fileLabel`: the path to the file where to find labels informations,
	- `ins`: instance object, it should be of type `instanceGA`. 

Reads the labels and returns a labels structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.read_labels-Tuple{String, abstractInstanceMCND}" href="#LearningPi.read_labels-Tuple{String, abstractInstanceMCND}"><code>LearningPi.read_labels</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs"># Arguments:
	- `fileLabel`: the path to the file where to find labels informations,
	- `ins`: instance object, it should be of type abstractInstanceMCND. 

Read the labels and returns a labels structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.read_labels-Tuple{String, instanceCWL}" href="#LearningPi.read_labels-Tuple{String, instanceCWL}"><code>LearningPi.read_labels</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">	- `fileLabel`: the path to the file where to find labels informations
	- `ins`: instance object, it should be of type sub-type of `instanceCWL` 

Reads the labels and returns a labels structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.rhs-Tuple{Instances.instanceGA, Any, Any}" href="#LearningPi.rhs-Tuple{Instances.instanceGA, Any, Any}"><code>LearningPi.rhs</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`ins`: an instances (of type `abstractInstanceGA`),
- `k`: useless parameter, only for signature,
- `i`: bin index.</code></pre><p>Return the right hand side of the dualized constraint associated to the bin <code>i</code> in <code>ins</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.rhs-Tuple{abstractInstanceMCND, Any, Any}" href="#LearningPi.rhs-Tuple{abstractInstanceMCND, Any, Any}"><code>LearningPi.rhs</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`ins`: an instances (of type `abstractInstanceMCND`),
- `k`: commodity index,
- `i`: vertex index.</code></pre><p>Return the right hand side of the dualized constraint associated to the commodity <code>k</code> and the vertex <code>i</code> in <code>ins</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.rhs-Tuple{instanceCWL, Any, Any}" href="#LearningPi.rhs-Tuple{instanceCWL, Any, Any}"><code>LearningPi.rhs</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`ins`: an instances (of type `instanceCWL`),
- `k`: useless parameter, only for signature,
- `i`: warehouse index.</code></pre><p>Return the right hand side of the dualized constraint associated to the warehouse <code>i</code> in <code>ins</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.saveHP-Tuple{String, Float32, Float32, Vector{Int64}, Any, LearningPi.learningGNN, LearningPi.abstract_features_matrix, LearningPi.abstract_deviation, Any, Int64, Int64, Vararg{Any, 7}}" href="#LearningPi.saveHP-Tuple{String, Float32, Float32, Vector{Int64}, Any, LearningPi.learningGNN, LearningPi.abstract_features_matrix, LearningPi.abstract_deviation, Any, Int64, Int64, Vararg{Any, 7}}"><code>LearningPi.saveHP</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>endString</code>: a string used as name for the output file,</li><li><code>lr</code>: learning rate of the algorithm,</li><li><code>decay</code>: decay for the learning rate,</li><li><code>h</code>: a list of #(hidden layers), each component of h contains the number of nodes in</li></ul><pre><code class="nohighlight hljs"> the associated hidden layer,</code></pre><ul><li><code>opt</code>: optimizer,</li><li><code>lt</code>: learning type object,     </li><li><code>fmt</code>: features matrix type,</li><li><code>dt</code>: deviation type,</li><li><code>loss</code>: loss function,</li><li><code>seedDS</code>: random seed for the dataset generation,</li><li><code>seedNN</code>: random seed for the neural network parameters,</li><li><code>stepSize</code>: the step size for the decay scheduler of the optimizer,</li><li><code>nodes_number</code>: size (number of nodes) in the hidden reprensentation between each layer,</li><li><code>block_number</code>: number of blocks in the model,</li><li><code>hI</code>: sizes of Dense layers in the first part, where the nodes features are sent in the hidden space,</li><li><code>hF</code>: sizes of Dense layers in the final,</li><li><code>dataPath</code>: path to the instances used in the dataset,</li><li><code>factory</code>: instance factory type.</li></ul><p>This function memorize all this hyper parameters in a JSON file.     </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.saveHP-Tuple{String, Float32, Float32, Vector{Int64}, Any, LearningPi.learningType, Any, Int64, Int64, Any}" href="#LearningPi.saveHP-Tuple{String, Float32, Float32, Vector{Int64}, Any, LearningPi.learningType, Any, Int64, Int64, Any}"><code>LearningPi.saveHP</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>endString</code>: a string used as name for the output file,</li><li><code>lr</code>: learning rate of the algorithm,</li><li><code>decay</code>: decay for the learning rate,</li><li><code>h</code>: a list of #(hidden layers), each component of h contains the number of nodes in</li></ul><pre><code class="nohighlight hljs"> the associated hidden layer,</code></pre><ul><li><code>opt</code>: optimizer,</li><li><code>lt</code>: learning type object,     </li><li><code>loss</code>: loss function,</li><li><code>seedDS</code>: random seed for the dataset generation,</li><li><code>seedNN</code>: random seed for the neural network parameters,</li><li><code>stepSize</code>: the step size for the decay scheduler of the optimizer.</li></ul><p>This function memorize all this hyper parameters in a JSON file.     </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sizeFeatures-Tuple{LearningPi.learningGNN, Any}" href="#LearningPi.sizeFeatures-Tuple{LearningPi.learningGNN, Any}"><code>LearningPi.sizeFeatures</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learning type, it should be a sub-type of <code>learningGNN</code>,</li><li><code>dS</code>: a dataset.</li></ul><p>Return the size of the features matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sizeFeatures-Tuple{LearningPi.learningMLP, Any}" href="#LearningPi.sizeFeatures-Tuple{LearningPi.learningMLP, Any}"><code>LearningPi.sizeFeatures</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code> : learning type (general),</li><li><code>dS</code> : dataset (corpus structure).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_constraint-Tuple{LearningPi.cr_features_matrix}" href="#LearningPi.size_features_constraint-Tuple{LearningPi.cr_features_matrix}"><code>LearningPi.size_features_constraint</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the constraints. In this case 6.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_constraint-Tuple{LearningPi.lr_features_matrix}" href="#LearningPi.size_features_constraint-Tuple{LearningPi.lr_features_matrix}"><code>LearningPi.size_features_constraint</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the constraints. In this case 6.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_constraint-Tuple{LearningPi.without_cr_features_matrix}" href="#LearningPi.size_features_constraint-Tuple{LearningPi.without_cr_features_matrix}"><code>LearningPi.size_features_constraint</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the constraints. In this case 4.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_variable-Tuple{LearningPi.cr_features_matrix}" href="#LearningPi.size_features_variable-Tuple{LearningPi.cr_features_matrix}"><code>LearningPi.size_features_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the variables. In this case 4.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_variable-Tuple{LearningPi.lr_features_matrix}" href="#LearningPi.size_features_variable-Tuple{LearningPi.lr_features_matrix}"><code>LearningPi.size_features_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the variables. In this case 4.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.size_features_variable-Tuple{LearningPi.without_cr_features_matrix}" href="#LearningPi.size_features_variable-Tuple{LearningPi.without_cr_features_matrix}"><code>LearningPi.size_features_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>fmt</code>: feature matrix type (it should be <code>cr_features_matrix</code>).</p><p>returns the size of the features associated to the variables. In this case 2.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.abstract_loss}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.abstract_loss}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers vector candidate, </li><li><code>v</code>: the value of the loss function,</li><li><code>example</code>: dataset sample object,</li><li><code>_</code>: loss parameters.</li></ul><p>Compute the value of the sub-problem for the loss for which it cannot be obtained in a smarter way.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_GAP}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_GAP}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers (are not used in this implementation),</li><li><code>v</code>: loss function value,</li><li><code>example</code>: an abstract_example,</li><li><code>_</code>: loss function. </li></ul><p>Compute the sub-problem value without solving the Lagrangian Sub-Problem, if it is already solved during the computation of the loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_LR_gpu}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_LR_gpu}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers (are not used in this implementation),</li><li><code>v</code>: loss function value,</li><li><code>example</code>: an abstract_example,</li><li><code>_</code>: loss function .</li></ul><p>Compute the sub-problem value without solving the Lagrangian Sub-Problem, if it is already solved during the computation of the loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_LR}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_LR}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers (are not used in this implementation),</li><li><code>v</code>: loss function value,</li><li><code>_</code>: an abstract_example,</li><li><code>_</code>: loss function. </li></ul><p>Compute the sub-problem value without solving the Lagrangian Sub-Problem, if it is already solved during the computation of the loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_hinge}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, Any, LearningPi.loss_hinge}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers vector candidate, </li><li><code>v</code>: the value of the loss function,</li><li><code>example</code>: dataset sample object,</li><li><code>_</code>: loss parameters, it should be a structure of type HingeLoss.   </li></ul><p>Compute the value of the sub-problem without recomputing it, but using the value of the loss function (for the HingeLoss)  and other informations contained in the sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.sub_problem_value-Tuple{Any, Any, LearningPi.abstract_example, LearningPi.loss_GAP_closure}" href="#LearningPi.sub_problem_value-Tuple{Any, Any, LearningPi.abstract_example, LearningPi.loss_GAP_closure}"><code>LearningPi.sub_problem_value</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: lagrangian multipliers (are not used in this implementation),</li><li><code>v</code>: loss function value,</li><li><code>example</code>: an abstract_example,</li><li><code>_</code>: loss function. </li></ul><p>Compute the sub-problem value without solving the Lagrangian Sub-Problem, if it is already solved during the computation of the loss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.testAndPrint-Tuple{Dict, Any, Any, Any, LearningPi.learningType, LearningPi.abstract_deviation}" href="#LearningPi.testAndPrint-Tuple{Dict, Any, Any, Any, LearningPi.learningType, LearningPi.abstract_deviation}"><code>LearningPi.testAndPrint</code></a> — <span class="docstring-category">Method</span></header><section><div><p>function testAndPrint(currentMetrics::Dict,testSet,nn,loss,loss,lt::learningType)</p><p><strong>Arguments:</strong></p><ul><li><code>currentMetrics</code>: a dictionary of Floats that contains several metric for the current epoch, </li><li><code>testSet</code> : a vector of example that correspond to the test set,</li><li><code>nn</code> : a neural network model.</li><li><code>loss</code>: a structure that encode the loss function.</li><li><code>lt</code>: learning type object.     </li></ul><p>This function compute different metrics over the validation set. The values are memorized in the dictionary and print them in the standard output.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.validation-Tuple{Dict, Any, Any, Any, LearningPi.learningType, LearningPi.abstract_deviation}" href="#LearningPi.validation-Tuple{Dict, Any, Any, Any, LearningPi.learningType, LearningPi.abstract_deviation}"><code>LearningPi.validation</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>currentMetrics</code>: a dictionary of Float, </li><li><code>valSet</code> : a vector of gnn_dataset that correspond to the validation set,</li><li><code>nn</code> : a neural network model,</li><li><code>loss</code>: a structure with the parameters of the loss,</li></ul><pre><code class="nohighlight hljs">	   For other details of the parameters of a certain loss see the definition of the particular structure of the loss,</code></pre><ul><li><code>loss</code>: loss function,</li><li><code>lt</code>: learning type object,       </li><li><code>dt</code>: deviation type (0 or dual of the CR).        </li></ul><p>This function compute different metrics over the validation set. The values are memorized in the dictionary.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api_public/">« Public APIs</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 17 June 2024 16:21">Monday 17 June 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
