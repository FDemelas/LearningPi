<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public APIs · LearningPi.jl</title><meta name="title" content="Public APIs · LearningPi.jl"/><meta property="og:title" content="Public APIs · LearningPi.jl"/><meta property="twitter:title" content="Public APIs · LearningPi.jl"/><meta name="description" content="Documentation for LearningPi.jl."/><meta property="og:description" content="Documentation for LearningPi.jl."/><meta property="twitter:description" content="Documentation for LearningPi.jl."/><meta property="og:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_public/"/><meta property="twitter:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_public/"/><link rel="canonical" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/api_public/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LearningPi.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Loss/">Loss Functions</a></li><li><a class="tocitem" href="../Models/">Machine Learning Models</a></li><li><a class="tocitem" href="../Sampling/">Sampling Mechanism</a></li><li><a class="tocitem" href="../Training/">Training Scripts</a></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../api/">API index</a></li><li class="is-active"><a class="tocitem" href>Public APIs</a></li><li><a class="tocitem" href="../api_private/">Private APIs</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API reference</a></li><li class="is-active"><a href>Public APIs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public APIs</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Public-API-for-LearningPi.jl"><a class="docs-heading-anchor" href="#Public-API-for-LearningPi.jl">Public API for LearningPi.jl</a><a id="Public-API-for-LearningPi.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Public-API-for-LearningPi.jl" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createCorpus" href="#LearningPi.createCorpus"><code>LearningPi.createCorpus</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>featType</code> : the type of the features instance,</li><li><code>folder</code> : the path to the directory that contains the json files that defines the instances (and the associated features and labels),</li><li><code>maxInstance</code> : a vector with three components,  that say how many instances take for the training/validation/test set,</li><li><code>seed</code> : a random seed used to select which instaces consider in the training/validation/test sets,</li><li><code>factory</code>: type of instance,</li><li><code>pTrain</code> : The percentage of training instances in the provided folder,</li><li><code>pVal</code> : The percentage of validation instances in the provided folder.</li></ul><p>Create a Corpus, that is a structure with three DataSet field for training,validation and test dataset. Note: The percentage for the test set will be 1-pTrain-pVal. It is important to select the percentage of training and validation in such a way that pTrain+pVal&lt;1 and both will be non-negative.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createDataSet" href="#LearningPi.createDataSet"><code>LearningPi.createDataSet</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: the learning type.</li><li><code>directory</code>: a list of paths to the instances.</li><li><code>maxInstance</code>: the maximum number of instances that we wat consider in the provided directory. By default is equal to <code>-1</code>, that means consider all the instances in the directory.</li><li><code>factory</code>: type of instance, the possibilities in this moment are cpuMCNDinstanceFactory() (that is Multi-Commodity Network-Design instances) and cpuCWLinstanceFactory() (for the Bin Packing instances).</li></ul><p>Create the dataset for the provided (general) learning type. return a dataSet structure of a proper type.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createDataSet" href="#LearningPi.createDataSet"><code>LearningPi.createDataSet</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">	- `lt`:learning type, it should be a sub-type of `learningGNN`, 
	- `directory`: the path to the directory containing instances,
	- `maxInstance`: maximum instance number, 
	- `factory`: instance factory, generic sub-type of `abstractInstanceFactory`.

Create and return a dataset for the provided learning type `lt`, considering `maxInst` instances of the factory `factory`, contained in `directory`</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createKfold" href="#LearningPi.createKfold"><code>LearningPi.createKfold</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>featType</code> : the type of the features instance,</li><li><code>folder</code> : the path to the directory that contains the json files that defines the instances (and the associated features and labels),</li><li><code>maxInstance</code> : a vector with three components,  that say how many instances take for the training/validation/test set,</li><li><code>seed</code> : a random seed used to select which instaces consider in the training/validation/test sets,</li><li><code>factory</code>: type of instance,</li><li><code>k</code>: the fold that we want select as test set. Note: 1 &lt;= k &lt;= 10.</li></ul><p>Create a Corpus, that is a struct with three DataSet field for training/validation/test set.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createLabels-Tuple{Any, Any, Any, Any, Any, abstractInstanceMCND}" href="#LearningPi.createLabels-Tuple{Any, Any, Any, Any, Any, abstractInstanceMCND}"><code>LearningPi.createLabels</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>π</code>: a (optimal) Lagrangian multipliers vector</li><li><code>x</code>: the flow variables in the Lagrangian sub-problem, obtained afer the resolution of the sub-problem with multipliers π,</li><li><code>y</code>: the design variables in the Lagrangian sub-problem, obtained afer the resolution of the sub-problem with multipliers π,</li><li><code>LRarcs</code>: a vector containign the bounds for each edge of the Lagrangian sub-problem considering π as Lagrangian multipleirs vector,</li><li><code>objLR</code>: the bound of the Lagrangian sub-problem considering π as Lagrangian multipleirs vector,</li><li><code>ins</code>: the instance structure (standard instance formulation, without regularization).</li></ul><pre><code class="nohighlight hljs">Return a proper label structure.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createLabels-Tuple{Any, Any, Any, Any, instanceCWL}" href="#LearningPi.createLabels-Tuple{Any, Any, Any, Any, instanceCWL}"><code>LearningPi.createLabels</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>π</code>: optimal lagrangian multipliers vector, -<code>x</code>: primal solution of the Knapsack Lagrangian Relaxation associated to the variables that associate one items to a pack (using the optimal Lagrangian multipliers), -<code>y</code>: primal solution of the Knapsack Lagrangian Relaxation associated to the variables say if we use or not a pack (using the optimal Lagrangian multipliers), -<code>objLR</code>: optimal value of the Lagrangian Dual,</p><ul><li><code>ins</code>: instance object, it should be of type sub-type of <code>instanceCWL</code>. </li></ul><p>Given all the fields construct a label structure for the Capacitated Warehouse Location Problem.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.createLabels-Tuple{Any, Any, Any, Instances.instanceGA}" href="#LearningPi.createLabels-Tuple{Any, Any, Any, Instances.instanceGA}"><code>LearningPi.createLabels</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">-`π`: optimal lagrangian multipliers vector,
-`x`: primal solution of the Knapsack Lagrangian Relaxation associated to the variables that associate one items to a pack (using the optimal Lagrangian multipliers),
-`objLR`: optimal value of the Lagrangian Dual,
- `ins`: instance object, it should be of type `instanceGA`.</code></pre><p>Given all the fields construct a label structure for the Generalized Assignment Problem.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_example-Tuple{LearningPi.learningGNN, String, abstractInstanceFactory, LearningPi.abstract_features_matrix}" href="#LearningPi.create_example-Tuple{LearningPi.learningGNN, String, abstractInstanceFactory, LearningPi.abstract_features_matrix}"><code>LearningPi.create_example</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learning Type, this function works for all the learning types that use a graph representation of the instance,</li><li><code>fileName</code>: path to the json that contains all the information to construct the learning sample starting from an instance, its features and the labels,</li><li><code>factory</code>: instance factory, it works for all the factory.</li></ul><p>Returns an <code>gnnExample_instance</code> with all the information useful for the training.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_example-Tuple{LearningPi.learningMLP, String, abstractInstanceFactory, Any}" href="#LearningPi.create_example-Tuple{LearningPi.learningMLP, String, abstractInstanceFactory, Any}"><code>LearningPi.create_example</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li>lt: learning type, it should be learningMLP,</li><li>fileName: the name of the file json that contains the informations about the instance, its features and its labels,</li><li>factory: type of instance (it handle both with the normalized and un-normalized instances).</li></ul><p>Create a structure containing the instance, the extracted features and the associated labels.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss" href="#LearningPi.create_loss"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>:</code>: loss parameters, it should be a structure of type HingeLoss.   </p><p>return the loss correspondent to loss paramameters of type HingeLoss.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss-Tuple{LearningPi.loss_GAP_closure_factory}" href="#LearningPi.create_loss-Tuple{LearningPi.loss_GAP_closure_factory}"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: a factory, for this implentation it should be of type ~<code>loss_GAP_closure_factory</code>.</li></ul><p>Return a loss corresponding to the factory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss-Tuple{LearningPi.loss_GAP_factory}" href="#LearningPi.create_loss-Tuple{LearningPi.loss_GAP_factory}"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: a factory, for this implentation it should be of type ~<code>loss_GAP_factory</code>.</li></ul><p>Return a loss corresponding to the factory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss-Tuple{LearningPi.loss_LR_factory}" href="#LearningPi.create_loss-Tuple{LearningPi.loss_LR_factory}"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: a factory, for this implentation it should be of type ~<code>loss_LR_factory</code>.</li></ul><p>Return a loss corresponding to the factory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss-Tuple{LearningPi.loss_LR_gpu_factory}" href="#LearningPi.create_loss-Tuple{LearningPi.loss_LR_gpu_factory}"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: a factory, for this implentation it should be of type ~<code>loss_LR_gpu_factory</code>.</li></ul><p>Return a loss corresponding to the factory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_loss-Tuple{LearningPi.loss_mse_factory}" href="#LearningPi.create_loss-Tuple{LearningPi.loss_mse_factory}"><code>LearningPi.create_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>_</code>: a factory, for this implentation it should be of type ~<code>loss_mse_factory</code>.</li></ul><p>Return a loss corresponding to the factory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningSampleNair</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningSampleNair</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningMultiPredSample</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningMultiPredSample</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningSampleTransformer</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningSampleTransformer</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningSampleGasse</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningSampleGasse</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: general learningType,</li><li><code>in</code>: size of the input layer,</li><li><code>h</code>: a vector with the same length as the desired number of hidden layers and each component say how many nodes we want in the correspondent hidden layer,</li><li><code>out</code>: size of the output layer, by default is equal to one,</li><li><code>a</code>: the activation function for the hidden layers, by default is <code>relu</code>.</li></ul><p>This function creates a model for the provided learning type (in order to use this variant it should be learningArc). The model is a multi layer perceptron with <code>in</code> nodes in the first layer, <code>length(h)</code> hidden layers (the i-th layer has <code>h[i]</code> nodes) and <code>out</code> nodes in the output layer (by default 1). By default each hidden layer use a relu activation function (the input and output layers have no activation function).   </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningSampleOutside</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningSampleOutside</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningTransformer</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningTransformer</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lType</code>: learning type, should be <code>learningMultiPredTransformer</code>, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>h</code>:  a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, </li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>a</code>: activation function, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>,</li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default  <code>[500, 250, 100]</code>,</li><li><code>hF</code>: a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>block_number</code>: number of main-blocks that compose the core part of the encoder, by default <code>5</code>,</li><li><code>nodes_number</code>: dimension of the hidden-space for the features representation, by default <code>500</code>,</li><li><code>pDrop</code>: drop-out parameter, by default <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>final_A</code>: final activation function (in the space of Lagrangian multipliers, but before deviation), by default <code>identity</code>.</li></ul><p>Returns the neural network model for <code>learningMultiPredTransformer</code> and the other provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.create_model" href="#LearningPi.create_model"><code>LearningPi.create_model</code></a> — <span class="docstring-category">Function</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>where_sample</code>: a structure composed by three booleans to say where perform sampling, </li><li><code>in</code>: size of the input of the neural network, for each node in the bipartite graph-representation, </li><li><code>nBlocks</code>: number of main-blocks that compose the core part of the encoder,</li><li><code>nNodes</code>: dimension of the hidden-space for the features representation,</li><li><code>out</code>: the dimention of the output of the neural network model, for each dualized constraint, by default 1,</li><li><code>act</code>: activation function for the parallel MLP, by default <code>relu</code>,</li><li><code>act_conv</code>: activation function for the Graph-Convolutional Layers, by default <code>relu</code>,</li><li><code>seed</code>: random generation seed, by default <code>1</code>, </li><li><code>hI</code>: a vector containing the number of nodes in the hidden layers that composes the initial MLP that send the features into the hidden space representation, by default <code>[100,250,500]</code>,</li><li><code>hH</code>:   a vector containing the number of nodes in the hidden layers that composes the  MLP inside the main-blocks of the Encoder, by default <code>[500]</code> ,</li><li><code>hF</code>:  a vector containing the number of nodes in the hidden layers that composes the final MLP in the Decoder, by default <code>[500, 250, 100]</code>,</li><li><code>pDrop</code>: drop-out parameter, by default  <code>0.001</code>,</li><li><code>dt</code> : deviation type, by default  <code>cr_deviation()</code>,</li><li><code>std</code>: standard deviation used for the initialization of the nn parameters, by default <code>0.00001</code>,</li><li><code>norm</code>: a boolean to say if normalize or not during the GNN message passing, by default <code>true</code>,</li><li><code>aggr</code>: the aggregation function, by default <code>mean</code>,</li><li><code>prediction_layers</code>: a vector that contains the indexes of the layers in which we want perform a prediction, by default <code>[]</code>, in this case we use the decoder only in the last main-block of the Graphormer.</li></ul><p>returns a model as defined in <code>Graphormer.jl</code> using the provided hyper-parameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.dataLoader-Tuple{String, Instances.cpuGAinstanceFactory}" href="#LearningPi.dataLoader-Tuple{String, Instances.cpuGAinstanceFactory}"><code>LearningPi.dataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments</strong></p><pre><code class="nohighlight hljs">- `fileName` : a path to a json file that contains the data for the instance, features and labels
- `factory` : an instance factory for the Generalized Assignment problem</code></pre><p>This function reads the instance, the features and the labels from the json and returns three structures that contains all the informations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.dataLoader-Tuple{String, MCNDinstanceFactory}" href="#LearningPi.dataLoader-Tuple{String, MCNDinstanceFactory}"><code>LearningPi.dataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments</strong></p><pre><code class="nohighlight hljs">- `fileName` : a path to a json file that contains the data for the instance, features and labels,
- `factory` : an instance object (for the same instance as the features file).</code></pre><p>It reads the instance, the features and the labels from the json and returns three structures that contains all the informations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.dataLoader-Tuple{String, cpuCWLinstanceFactory}" href="#LearningPi.dataLoader-Tuple{String, cpuCWLinstanceFactory}"><code>LearningPi.dataLoader</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments</strong></p><pre><code class="nohighlight hljs">- `fileName` : a path to a json file that contains the data for the instance, features and labels,
- `factory` : an instance factory for the Capacitated Warehouse Location problem.</code></pre><p>It reads the instance, the features and the labels from the json located in <code>fileName</code> and returns three structures that contains all the informations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresExtraction-Tuple{LearningPi.learningMLP, Any, abstractInstance}" href="#LearningPi.featuresExtraction-Tuple{LearningPi.learningMLP, Any, abstractInstance}"><code>LearningPi.featuresExtraction</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>featType</code> features type,</li><li><code>features</code> a features matrix,</li><li><code>nbFeatures</code> the number of features.</li></ul><p>Vectorization function for the features when we consider a learningNodeDemand encoding.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, Instances.instanceGA, LearningPi.abstract_features_matrix}" href="#LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, Instances.instanceGA, LearningPi.abstract_features_matrix}"><code>LearningPi.featuresExtraction</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learnign type, it should be a sub-type of learningType,</li><li><code>featObj</code>: features object containing all the characteristics, </li><li><code>ins</code>: instance structure, it should instanceGA,</li><li><code>fmt</code>: features matrix type.</li></ul><p>Returns the bipartite graph representation with the associated nodes-features matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, abstractInstanceMCND, LearningPi.abstract_features_matrix}" href="#LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, abstractInstanceMCND, LearningPi.abstract_features_matrix}"><code>LearningPi.featuresExtraction</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learnign type, it should be a sub-type of learningGNN,</li><li><code>featObj</code>: features object containing all the characteristics,</li><li><code>ins</code>: instance structure, it should be a sub-type of abstractInstanceMCND.</li></ul><p>Returns the bipartite graph representation with the associated nodes-features matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, instanceCWL, LearningPi.abstract_features_matrix}" href="#LearningPi.featuresExtraction-Tuple{LearningPi.learningType, Any, instanceCWL, LearningPi.abstract_features_matrix}"><code>LearningPi.featuresExtraction</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>lt</code>: learnign type, it should be a sub-type of <code>learningType</code>,</li><li><code>featObj</code>: features object containing all the characteristics, </li><li><code>ins</code>: instance structure, it should <code>instanceCWL</code>,</li><li><code>fmt</code>: features matrix type.</li></ul><p>Returns the bipartite graph representation with the associated nodes-features matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.prediction-Tuple{Flux.Chain, Any, Any, LearningPi.learningMLP, LearningPi.abstract_deviation}" href="#LearningPi.prediction-Tuple{Flux.Chain, Any, Any, LearningPi.learningMLP, LearningPi.abstract_deviation}"><code>LearningPi.prediction</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><p>-<code>nn</code>: neural network model, -<code>f</code>: features matrix, -<code>ins</code>: structure containing the instance informations, -<code>lt</code>: learning type (general).</p><p>provide the predicted Lagrangian multipliers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LearningPi.train-Tuple{Int64, LearningPi.Corpus, Any, Flux.Optimise.Optimiser, LearningPi.abstract_loss}" href="#LearningPi.train-Tuple{Int64, LearningPi.Corpus, Any, Flux.Optimise.Optimiser, LearningPi.abstract_loss}"><code>LearningPi.train</code></a> — <span class="docstring-category">Method</span></header><section><div><p><strong>Arguments:</strong></p><ul><li><code>maxEp</code>: the maximum number of epochs for the learning algorithm,</li><li><code>dS</code>: the Corpus structure that contains the training, validation and test sets,</li><li><code>nn</code>: the neural network model,</li><li><code>opt</code>: the optimizer used for the training,</li><li><code>loss</code>: a structure that contains the parameters α and β of the loss,</li><li><code>printEpoch</code>: the number of epochs in which print the metrics of the training,</li><li><code>endString</code>: the string used to memorize the output files as best models and tensorboard logs,</li><li><code>dt</code>: deviation type, it could deviate from zero or the duals of the continuous relaxation,</li><li><code>lt</code>: learning type,</li><li><code>seed</code>: random seed for the random generators,</li><li><code>bs</code> batch size.</li></ul><p>This function performs the learning with the provided inputs and save the best models in a bson file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« API index</a><a class="docs-footer-nextpage" href="../api_private/">Private APIs »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 17 June 2024 16:21">Monday 17 June 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
