<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Machine Learning Models · LearningPi.jl</title><meta name="title" content="Machine Learning Models · LearningPi.jl"/><meta property="og:title" content="Machine Learning Models · LearningPi.jl"/><meta property="twitter:title" content="Machine Learning Models · LearningPi.jl"/><meta name="description" content="Documentation for LearningPi.jl."/><meta property="og:description" content="Documentation for LearningPi.jl."/><meta property="twitter:description" content="Documentation for LearningPi.jl."/><meta property="og:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/Models/"/><meta property="twitter:url" content="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/Models/"/><link rel="canonical" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/Learning_Lagrangian_Multipliers.jl/Models/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LearningPi.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Loss/">Loss Functions</a></li><li class="is-active"><a class="tocitem" href>Machine Learning Models</a><ul class="internal"><li><a class="tocitem" href="#General-Models"><span>General Models</span></a></li><li><a class="tocitem" href="#Some-Easy-to-Repeat-Models"><span>Some Easy-to-Repeat Models</span></a></li><li><a class="tocitem" href="#References:"><span>References:</span></a></li></ul></li><li><a class="tocitem" href="../Sampling/">Sampling Mechanism</a></li><li><a class="tocitem" href="../Training/">Training Scripts</a></li><li><a class="tocitem" href="../api/">API reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Machine Learning Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Machine Learning Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FDemelas/Learning_Lagrangian_Multipliers.jl/-/blob/main/src/LearningPi.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="General-Models"><a class="docs-heading-anchor" href="#General-Models">General Models</a><a id="General-Models-1"></a><a class="docs-heading-anchor-permalink" href="#General-Models" title="Permalink"></a></h2><h3 id="MLP"><a class="docs-heading-anchor" href="#MLP">MLP</a><a id="MLP-1"></a><a class="docs-heading-anchor-permalink" href="#MLP" title="Permalink"></a></h3><p>A Classic Multi Layer Perceptron that receeives as input one features vector (for each dualized constraint) and predict (in parallel) one Lagrangian Multiplier Value (for each relaxed constraint).</p><h3 id="GNN-Models"><a class="docs-heading-anchor" href="#GNN-Models">GNN Models</a><a id="GNN-Models-1"></a><a class="docs-heading-anchor-permalink" href="#GNN-Models" title="Permalink"></a></h3><p>The key models of this project belongs from this family and can be all seen as particular instantiation of the more general model implemented in <code>Graphormer.jl</code>.</p><p>The key component of this model consists on the block presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>.</p><h2 id="Some-Easy-to-Repeat-Models"><a class="docs-heading-anchor" href="#Some-Easy-to-Repeat-Models">Some Easy-to-Repeat Models</a><a id="Some-Easy-to-Repeat-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Some-Easy-to-Repeat-Models" title="Permalink"></a></h2><p>In this section we will present some GNN models that are already implemented as partticular instantiation of the model defined in <code>Graphormer.jl</code>.</p><p>All the constructors for this models can be found in the file <code>ModelFactory.jl</code>.</p><h3 id="LearningTransformer"><a class="docs-heading-anchor" href="#LearningTransformer">LearningTransformer</a><a id="LearningTransformer-1"></a><a class="docs-heading-anchor-permalink" href="#LearningTransformer" title="Permalink"></a></h3><p>Simply consists on sequential Chain of the block presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, without Sampling Mechanism.</p><h3 id="LearningSampleTransformer"><a class="docs-heading-anchor" href="#LearningSampleTransformer">LearningSampleTransformer</a><a id="LearningSampleTransformer-1"></a><a class="docs-heading-anchor-permalink" href="#LearningSampleTransformer" title="Permalink"></a></h3><p>As <code>LearningTransformer</code>, the only difference is that for this model we consider the Sampling mechanism, as presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. </p><h3 id="LearningSampleGasse"><a class="docs-heading-anchor" href="#LearningSampleGasse">LearningSampleGasse</a><a id="LearningSampleGasse-1"></a><a class="docs-heading-anchor-permalink" href="#LearningSampleGasse" title="Permalink"></a></h3><p>As <code>LearningSampleTransformer</code> this architecture consider the same Sampling Mechanism presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. Insted of using ours architecture it use one more near to the one presented by Gasse et al. in <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>.</p><h3 id="LearningSampleNair"><a class="docs-heading-anchor" href="#LearningSampleNair">LearningSampleNair</a><a id="LearningSampleNair-1"></a><a class="docs-heading-anchor-permalink" href="#LearningSampleNair" title="Permalink"></a></h3><p>As <code>LearningSampleTransformer</code> this architecture consider the same Sampling Mechanism presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. Insted of using ours architecture it use one more near to the one presented by Nair et al. in <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup></p><h3 id="LearningSampleOutside"><a class="docs-heading-anchor" href="#LearningSampleOutside">LearningSampleOutside</a><a id="LearningSampleOutside-1"></a><a class="docs-heading-anchor-permalink" href="#LearningSampleOutside" title="Permalink"></a></h3><p>As <code>LearningTransformer</code>, the only difference is that for this model we consider a sampling mechanism. While <code>LearningSampleTransformer</code> sample in the hidden space (as presented in <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>), in this case we sample directly in the output space. More details on the sampling mechanism can be found in the apposite Section. </p><h3 id="LearningMultiPredTransformer"><a class="docs-heading-anchor" href="#LearningMultiPredTransformer">LearningMultiPredTransformer</a><a id="LearningMultiPredTransformer-1"></a><a class="docs-heading-anchor-permalink" href="#LearningMultiPredTransformer" title="Permalink"></a></h3><p>This model as the same inner structure as <code>LearningTransformer</code>, but it contains several decoders and so is able to provide several Lagrangian Multipliers prediction using the same model (maximum one for block). The model <code>LearningTransformer</code> can be seen as this model with only one decoder at the end of the Block Chain. No sample mechanism is used in this case.</p><h3 id="LearningMultiPredSample"><a class="docs-heading-anchor" href="#LearningMultiPredSample">LearningMultiPredSample</a><a id="LearningMultiPredSample-1"></a><a class="docs-heading-anchor-permalink" href="#LearningMultiPredSample" title="Permalink"></a></h3><p>This model as the same inner structure as <code>LearningSampleTransformer</code>, but it contains several decoders and so is able to provide several Lagrangian Multipliers prediction using the same model (maximum one for block). The model <code>LearningSampleTransformer</code> can be seen as this model with only one decoder at the end of the Block Chain. The sampling mechanism is the same as <code>LearningSampleTransformer</code> for each predicted Lagrangian Multipliers vector.</p><h2 id="References:"><a class="docs-heading-anchor" href="#References:">References:</a><a id="References:-1"></a><a class="docs-heading-anchor-permalink" href="#References:" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>F. Demelas, J. Le Roux, M. Lacroix, A. Parmentier &quot;Predicting Lagrangian Multipliers for Mixed Integer Linear Programs&quot;, ICML 2024.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Gasse, M., Chételat, D., Ferroni, N., Charlin, L., and Lodi, A. Exact Combinatorial Optimization with Graph Convolutional Neural Networks. In Wallach, H., Larochelle, H., Beygelzimer, A., Alché-Buc, F. d., Fox, E., and Garnett,R. (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Nair, V., Bartunov, S., Gimeno, F., von Glehn, I., Lichocki, P., Lobov, I., O’Donoghue, B., Sonnerat, N., Tjandraatmadja, C., Wang, P., Addanki, R., Hapuarachchi, T., Keck, T., Keeling, J., Kohli, P., Ktena, I., Li, Y., Vinyals, O., and Zwols, Y. Solving mixed integer programs using neural networks. CoRR, abs/2012.13349, 2020.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Loss/">« Loss Functions</a><a class="docs-footer-nextpage" href="../Sampling/">Sampling Mechanism »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Tuesday 4 June 2024 07:35">Tuesday 4 June 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
